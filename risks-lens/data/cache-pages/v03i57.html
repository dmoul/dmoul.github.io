<!DOCTYPE html>
<html lang="en" itemscope="" itemtype="http://schema.org/WebPage" prefix="og: http://ogp.me/ns#">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>The RISKS Digest Volume 3 Issue 57</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="apple-touch-icon-precomposed" sizes="57x57" href="/Risks/assets/favicons/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/Risks/assets/favicons/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/Risks/assets/favicons/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/Risks/assets/favicons/apple-touch-icon-144x144.png">
<link rel="apple-touch-icon-precomposed" sizes="60x60" href="/Risks/assets/favicons/apple-touch-icon-60x60.png">
<link rel="apple-touch-icon-precomposed" sizes="120x120" href="/Risks/assets/favicons/apple-touch-icon-120x120.png">
<link rel="apple-touch-icon-precomposed" sizes="76x76" href="/Risks/assets/favicons/apple-touch-icon-76x76.png">
<link rel="apple-touch-icon-precomposed" sizes="152x152" href="/Risks/assets/favicons/apple-touch-icon-152x152.png">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-196x196.png" sizes="196x196">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-128.png" sizes="128x128">
<meta name="application-name" content="The Risks Digest">
<meta name="msapplication-TileColor" content="#FFFFFF">
<meta name="msapplication-TileImage" content="/Risks/assets/favicons/mstile-144x144.png">
<meta name="msapplication-square70x70logo" content="/Risks/assets/favicons/mstile-70x70.png">
<meta name="msapplication-square150x150logo" content="/Risks/assets/favicons/mstile-150x150.png">
<meta name="msapplication-wide310x150logo" content="/Risks/assets/favicons/mstile-310x150.png">
<meta name="msapplication-square310x310logo" content="/Risks/assets/favicons/mstile-310x310.png">
<link rel="stylesheet" href="/Risks/assets/css/rlayout.min.css" media="screen">
<link rel="Up" href="/Risks/">
<link rel="Contents" href="/Risks/">
<link rel="Help" href="/Risks/">
<link rel="Home" href="/Risks/">
<link rel="Search" href="/Risks/search">
<link rel="First" href="/Risks/1/1">
<link rel="Last" href="/Risks/latest">
<link rel="Copyright" href="/Risks/info.html#cpr">
<link rel="alternate" href="/rdigest.rdf" type="application/rss+xml" title="RSS">
<link rel="alternate" href="/risksrss1.xml" type="application/rss+xml" title="RSS 1.0">
<link rel="alternate" href="/risksrss2" type="application/rss+xml" title="RSS 2.0">
<link rel="alternate" href="/risksatom.xml" type="application/atom+xml" title="ATOM">
<link rel="alternate" href="/risks.json" type="application/json" title="JSON Feed">
<link rel="alternate" href="/risksgorss1.xml" type="application/rss+xml" title="RSS 1.0 WAP">
<link rel="alternate" href="/risksgorss2" type="application/rss+xml" title="RSS 2.0 WAP">
<link rel="alternate" href="/risksgoatom.xml" type="application/atom+xml" title="ATOM WAP">
<link rel="alternate" href="/risksgo.json" type="application/json" title="JSON Feed">
<link rel="Index" href="/Risks/3/index">
<link rel="Prev" href="/Risks/3/56">
<link rel="Next" href="/Risks/3/58">
<meta name="DC.Creator" content="Peter G. Neumann">
<meta name="DC.Title" content="The RISKS Digest, Volume 3 Issue 57">
<meta name="DC.Language" content="en">
<meta name="DC.Type" content="Text">
<meta name="DC.Format" content="text/html">
<meta property="og:title" content="The RISKS Digest, Volume 3 Issue 57">
<meta property="og:site_name" content="The Risks Digest">
<meta property="og:locale" content="en">
<meta property="og:type" content="website">
<meta name="citation_author" content="Peter G. Neumann">
<meta name="citation_title" content="The RISKS Digest, Volume 3 Issue 57">
<meta name="citation_journal_title" content="The RISKS Digest, Volume 3 Issue 57">
<meta name="DC.Date" content="1986-09-16">
<meta property="og:article:published_time" content="1986-09-16">
<meta name="citation_volume" content="3">
<meta name="citation_issue" content="57">
<meta name="citation_publication_date" content="1986/09/16">
</head>
<body lang="en-GB">
            <nav><div class="btns">
                                                <a href="/Risks/3/56" title="Volume 3 Issue 56" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-left"></i></a>
                                <a href="/Risks/3/index" title="Volume 3 Index" itemprop="relatedLink"><i class="fad fa-fw fa-list"></i></a>
                                                    <a href="/Risks/3/58" title="Volume 3 Issue 58" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-right"></i></a>
                                        <a href="mailto:risks@csl.sri.com" title="Submit an article to RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-envelope"></i></a>
            <a href="mailto:lindsay.marshall@newcastle.ac.uk?subject=Risks+Problem+3.57" title="Report a problem with this issue" itemprop="relatedLink"><i class="fad fa-fw fa-bug"></i></a>
            <a href="/Risks/archive/3/risks-3.57.gz" title="Fetch this issue as compressed plaintext" itemprop="relatedLink"><i class="fad fa-fw fa-cloud-download-alt"></i></a>
            <a href="/Risks/latest" title="The latest issue" itemprop="relatedLink"><i class="fad fa-fw fa-fast-forward"></i></a>
                            <a href="/Risks/" title="Information about RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-info"></i></a>
                                </div>
        <div class="srch">
            <form action="/Risks/search" method="get">
                <label>Search RISKS <input type="text" name="query" placeholder="Query String"></label>
                <button type="submit"><i class="fad fa-fw fa-search"></i></button>
            </form>
        </div>
        <div class="clear"></div>
    </nav><h1 class="cntr" itemprop="name">
<span class="rdigest">The RISKS Digest</span><br>Volume 3 Issue 57</h1>
            <h2 class="cntr">Tuesday, 16th September 1986</h2>
        <h3 class="cntr">Forum on Risks to the Public in Computers and Related Systems</h3>
    <h3 class="cntr">
	<i><a href="//www.acm.org">ACM</a> Committee on Computers and Public Policy,
	<a href="http://www.csl.sri.com/neumann/neumann.html">Peter G. Neumann</a>, moderator</i>
        </h3>

    <h3>Contents</h3>
    

<dl>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj1">Computers and the Stock Market (again)</a>
</dt>
<dd>
<a href="#subj1.1">Robert Stroud</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj2">The Old Saw about Computers and TMI</a>
</dt>
<dd>
<a href="#subj2.1">Ken Dymond</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj3">Do More Faults Mean (Yet) More Faults?</a>
</dt>
<dd>
<a href="#subj3.1">Dave Benson</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj4">A critical real-time application worked the first time</a>
</dt>
<dd>
<a href="#subj4.1">Dave Benson</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj5">Autonomous weapons</a>
</dt>
<dd>
<a href="#subj5.1">Eugene Miya</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj6">"Unreasonable behavior" and software</a>
</dt>
<dd>
<a href="#subj6.1">Eugene Miya on Gary Chapman</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj7">Risks of maintaining computer timestamps revisited</a>
</dt>
<dd>
<a href="#subj7.1">John Coughlin</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="/Risks">Info on RISKS (comp.risks)</a>
</dt>
</dl>
<a name="subj1" href="#subj1" id="subj1"><hr class="main"></a>
<h3>
<a name="subj1.1" href="#subj1.1" id="subj1.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Computers and the Stock Market (again)</h3>
<address>Robert Stroud &lt;robert%cheviot.newcastle.ac.uk@Cs.Ucl.AC.UK&gt;</address>
<i>Mon, 15 Sep 86 16:53:37 gmt</i>
<pre>
The computers had a hand in the dramatic fall on Wall Street last week
according to an item on the BBC TV news. Apparently, the systems were
not designed to cope with the sheer volume of sales, (anybody know more
about this?). The report continued

    "In London they still do it the old fashioned way with bits
    of paper, which makes people think twice before joining in
    a mindless selling spree. However, all this could change in
    October with the Big Bang..."

What price progress?

Robert Stroud,
Computing Laboratory,
University of Newcastle upon Tyne.

ARPA robert%cheviot.newcastle@ucl-cs.ARPA
UUCP ...!ukc!cheviot!robert

</pre>
<a name="subj2" href="#subj2" id="subj2"><hr class="main"></a>
<h3>
<a name="subj2.1" href="#subj2.1" id="subj2.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> The Old Saw about Computers and TMI</h3>
<address>"DYMOND, KEN" &lt;dymond@nbs-vms.ARPA&gt;</address>
<i>16 Sep 86 09:25:00 EDT</i>
<pre>
Ihor Kinal says in <a href="/Risks/3/55">RISKS-3.55</a>

    &gt;Obviously, one can present arguments for each side [human
    &gt; vs computer having the last say â€” at TMI, computers
    &gt;were right, but ...]   I would say that if humans do
    &gt;override CRITICAL computer control [like TMI], then
    &gt;some means of escalating the attention level must be
    &gt;invoked [e.g., have the computers automatically notify
    &gt;the NRC].

This belief keeps surfacing but is false.  There was no computer
control in safety grade systems at TMI â€” see the documentation in
the Kemeny report and probably elsewhere.  There was a computer in
the control room but it only drove a printer to provide a hardcopy
log of alarms in the sequence in which they occurred.  The log is
an aid in diagnosing events.  The computer (a Bendix G-15 ??) did 
play a role in the emergency since at one point its buffer became 
full and something like 90 minutes of alarms were not recorded, thus
hampering diagnosis.  

On a couple of occasions I have asked NRC people why computers aren't
used to control critical plant systems and have been told that "they aren't
safety grade."  I'm not quite sure what this means, but I take it
to mean that computers (and software) aren't trustworthy enough for
such safety areas as the reactor protection system.  This is not to
say that computers aren't used in monitoring plant status, quite
different from control.

Ken Dymond
(the opinions above don't necessarily reflect those of my employer
or anybody else, for that matter.)

</pre>
<a name="subj3" href="#subj3" id="subj3"><hr class="main"></a>
<h3>
<a name="subj3.1" href="#subj3.1" id="subj3.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Do More Faults Mean (Yet) More Faults?</h3>
<address>Dave Benson &lt;benson%wsu.csnet@CSNET-RELAY.ARPA&gt;</address>
<i>Sun, 14 Sep 86 19:00:30 pdt</i>
<pre>
  |In <a href="/Risks/3/50">RISKS 3.50</a> Dave Benson comments in "Flight Simulator
  |Simulators Have Faults" that
  |
  |    &gt;We need to understand that the more faults found at
  |    &gt;any stage to engineering software the less confidence one has in the
  |    &gt;final product.  The more faults found, the higher the likelyhood that
  |    &gt;faults remain.
  |
  |This statement makes intuitive sense, but does anyone know of any data
  |to support this ?  Is this true of any models of software failures ?
  |Is this true of the products in any of the hard engineering fields â€” civil,
  |mechanical, naval, etc. â€” and do those fields have the confirming data ?
  |
  |Ken Dymond, NBS

Please read the compendium of (highly readable) papers by M.M.Lehman and
L.A.Belady, Program Evolution: Processes of Software Change, APIC Studies
in Data Processing No. 27, Academic Press, Orlando, 1985.  This provides data.
It is (sorry-- should be, but probably isn't) standard in software quality
assurance efforts to throw away modules which show a high proportion of
the total evidenced failures.  The (valid, in my opinion) assumption is
that the engineering on these is so poor that it is hopeless to continue
to try to patch it up.

Certain models of software failure place increased "reliablity" on software
which has been exercised for long periods without fault.  One must
understand that this is simply formal modelling of the intuition that
some faults means (yet) more faults.  This is certainly true of all
engineering fields.  While I don't have the "confirming data" I suggest you
consider your car, your friends car, etc.  Any good history of engineering
will suggest that many designs never are marketed because of an unending
sequence of irremediable faults.

The intuitive explaination is: Good design and careful implementation works.
This is teleological.  We define good design and careful implementation by
"that which works".

However, I carefully said "confidence".  Confidence is an intuitive
assessment of reliability.  I was not considering the formalized notion
of "confidence interval" used in statistical studies.  To obtain high
confidence in the number of faults requires observing very many errors,
thus lowering one's confidence in the product.  To obtain high confidence
in a product requires observing very few errors while using it.

</pre>
<a name="subj4" href="#subj4" id="subj4"><hr class="main"></a>
<h3>
<a name="subj4.1" href="#subj4.1" id="subj4.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> I found one! (A critical real-time application worked the first time)</h3>
<address>Dave Benson &lt;benson%wsu.csnet@CSNET-RELAY.ARPA&gt;</address>
<i>Sun, 14 Sep 86 22:40:21 pdt</i>
<pre>
Last spring I issued a call for hard data to refute a hypothesis which I,
perhaps mistakenly, called the Parnas Hypothesis:
    No large computer software has ever worked the first time.
Actually, I was only interested in military software, so let me repost the
challenge in the form I am most interested in:
    NO MILITARY SOFTWARE (large or small) HAS EVER WORKED IN ITS FIRST
    OPERATIONAL TEST OR ITS FIRST ACTUAL BATTLE.
Contradict me if you can. (Send citations to the open literature
to benson@wsu via csnet)

Last spring's request for data has finally led to the following paper:
    Bonnie A. Claussen, II
    VIKING '75 â€” THE DEVELOPMENT OF A RELIABLE FLIGHT PROGRAM
    Proc. IEEE COMPSAC 77 (Computer Software &amp; Applications Conference)
    IEEE Computer Society, 1977
    pp. 33-37

I offer some quotations for your delictation:

    The 1976 landings of Viking 1 and Viking 2 upon the surface of
    Mars represented a significant achievement in the United States
    space exploration program. ... The unprecented success of the Viking
    mission was due in part to the ability of the flight software
    to operate in an autonomous and error free manner. ...
    Upon separation from the Oribiter the Viking Lander, under autonomous
    software control, deorbits, enters the Martian atmosphere,
    and performs a soft landing on the surface. ... Once upon the surface,
    ... the computer and its flight software provide the means by
    which the Lander is controlled.  This control is semi-autonomous
    in the sense that Flight Operations can only command the Lander
    once a day at 4 bit/sec rate.

(Progress occured in a NASA contract over a decade ago, in that)

    In the initial stages of the Viking flight program development,
    the decision was made to test the flight algorithms and determine
    the timing, sizing and accuracy requirements that should be 
    levied upon the flight computer prior to computer procurement.
    ... The entire philosophy of the computer hardware and
    software reliability was to "keep it simple."  Using the
    philosophy of simplification, modules and tasks tend toward 
    straight line code with minium decisions and minimum
    interactions with other modules.

(It was lots of work, as)

    When questioning the magnitude of the qulity assurance task,
    it should be noted that the Viking Lander flight program development
    required approximately 135 man-years to complete.

(But the paper gives no quantitative data about program size or complexity.)

Nevertheless, we may judge this as one of the finest software engineering
acomplishments to date.  The engineers on this project deserve far more
plaudits than they've received.  I know of no similar piece of software
with so much riding upon its reliable behavior which has done so well.
(If you do, please do tell me about it.)

However, one estimates that this program is on the order of kilolines of FORTRAN
and assembly code, probably less than one hundred kilolines.  Thus
Parnas will need to judge for himself whether or not the Viking Lander
flight software causes him to abandon (what I take to be) his hypothesis
about programs not working the first time.

It doesn't cause me to abandon mine because there were no Martians shooting
back, as far as we know...

David B. Benson, Computer Science Department, Washington State University,
Pullman, WA 99164-1210  csnet: benson@wsu

</pre>
<a name="subj5" href="#subj5" id="subj5"><hr class="main"></a>
<h3>
<a name="subj5.1" href="#subj5.1" id="subj5.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Autonomous weapons</h3>
<address>&lt;LIN@XX.LCS.MIT.EDU&gt;</address>
<i>Tue, 16 Sep 1986 08:31 EDT</i>
<pre>

    From: eugene at AMES-NAS.ARPA (Eugene Miya)

    ... another poster brought up the issue of autonmous weapons.
    We had a discussion of of this at the last Palo Alto CPSR meeting.
    Are autonmous weapons moral?  If an enemy has a white flag or hand-ups,
    is the weapon "smart enough" to know the Geneva Convention (or is too
    moral for programmers of such systems)?

What do you consider an autonomous weapon?  Some anti-tank devices are
intended to recognize tanks and then attack them without human
intervention after they have been launched (so-called fire-and-forget
weapons).  But they still must be fired under human control.  *People*
are supposed to recognize white flags and surrendering soldiers.

</pre>
<a name="subj6" href="#subj6" id="subj6"><hr class="main"></a>
<h3>
<a name="subj6.1" href="#subj6.1" id="subj6.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> "Unreasonable behavior" and software</h3>
<address>&lt;LIN@XX.LCS.MIT.EDU&gt;</address>
<i>Tue, 16 Sep 1986 09:01 EDT</i>
<pre>
    From: Gary Chapman <chapman at russell.stanford.edu information about targets can be placed into the munitions processor prior to firing along with updates on meteorologi- cal conditions and terrain. warhead functioning also selected as variable options will available. intro- duction of vhsic processors give terminal homing capability distinguishing between enemy friendly systems finite target type selection. since decision which attack is made board weapon thm approach human intelligence in this area. design criteria pointed toward one munition per kill. scratched my head rest you when i saw always thought if fire a bullet or shell out tube it goes until hits something preferably aiming at. but maybe army has some new theories ballistics we don know yet. an example what calls munition. being fires general direction then seeks its without further intervention. mechanisms alter course from ballistic trajectory. level confidence would have soldiers soldiers--we may get used using that caveat operating close proximity thms things are indeed question. own guess other smart never able distinguish friend foe. why most current concepts directed towards attacking forces deep behind lines where assume anything see hostile.><a name="subj7" href="#subj7" id="subj7"><hr class="main"></a>
<h3>
<a name="subj7.1" href="#subj7.1" id="subj7.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Risks of maintaining computer timestamps revisited</h3>
<address>John Coughlin &lt;JC%CARLETON.BITNET@WISCVM.WISC.EDU&gt;</address>
<i>15 Sep 86 12:14:00 EDT</i>
<pre>

Some  time ago I  submitted an item  to RISKS describing  the way in which the
CP-6 operating system  requires the time to be set  manually during every warm
or cold boot.  The latest release  of this OS contains an improvement: in most
cases the time need only be  manually set on a cold boot.  Unfortunately, with
this enhancement came an unusual bug.

The timestamp is  stored in a special hardware register,  which is modified by
certain  diagnostic procedures  run during  preventive maintenance.   It seems
these diagnostic  procedures were not modified  to reflect the new  use put to
the timestamp register.  As a result, any time a warm boot was performed after
PM,  the monitor  would freak  out at  the illegal  timestamp and mysteriously
abort the boot  with a memory fault.  Until this bug  was patched the only fix
was to power the computer down, thus clearing the offending value.

Luckily, the  PM procedure set the timestamp  register to an impossible value,
rather than a realistic but incorrect value.  Therefore the problem manifested
itself in  an obvious way, instead  of subtly changing the  date and time.  Of
course  this was  at the  cost of  having to  fix a  hung system.  This is yet
another illustration of the risk of breaking one thing while fixing another.

                                                                     /jc

</pre>

        <nav><div class="btns">
                                                <a href="/Risks/3/56" title="Volume 3 Issue 56" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-left"></i></a>
                                <a href="/Risks/3/index" title="Volume 3 Index" itemprop="relatedLink"><i class="fad fa-fw fa-list"></i></a>
                                                    <a href="/Risks/3/58" title="Volume 3 Issue 58" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-right"></i></a>
                                        <a href="mailto:risks@csl.sri.com" title="Submit an article to RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-envelope"></i></a>
            <a href="mailto:lindsay.marshall@newcastle.ac.uk?subject=Risks+Problem+3.57" title="Report a problem with this issue" itemprop="relatedLink"><i class="fad fa-fw fa-bug"></i></a>
            <a href="/Risks/archive/3/risks-3.57.gz" title="Fetch this issue as compressed plaintext" itemprop="relatedLink"><i class="fad fa-fw fa-cloud-download-alt"></i></a>
            <a href="/Risks/latest" title="The latest issue" itemprop="relatedLink"><i class="fad fa-fw fa-fast-forward"></i></a>
                            <a href="/Risks/" title="Information about RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-info"></i></a>
                                </div>
        <div class="srch">
            <form action="/Risks/search" method="get">
                <label>Search RISKS <input type="text" name="query" placeholder="Query String"></label>
                <button type="submit"><i class="fad fa-fw fa-search"></i></button>
            </form>
        </div>
        <div class="clear"></div>
    </nav><p class="problems">Please report problems with the web pages to <a href="mailto:lindsay.marshall@ncl.ac.uk?subject=Problem+with+RISKS+3.57">the maintainer</a></p>

    <div id="totop">
        <i class="fas fa-chevron-up"></i>Top
    </div>

    <script src="https://kit.fontawesome.com/f38fd5f4bf.js" crossorigin="anonymous"></script><script src="https://code.jquery.com/jquery-3.5.1.min.js"></script><script>
	var base = '/Risks';

	    function hostname(url)
    {
        var match = url.match(/:\/\/(www[0-9]?\.)?(.[^/:]+)/i);
        return match != null && match.length > 2 && typeof match[2] === 'string' && match[2].length > 0 ? match[2] : null;
    }

    function domain(url) {
        var host = hostname(url);
        
        if (host != null)
        {
            var parts = host.toLowerCase().split('.').reverse();
            
            if (parts != null && parts.length > 1)
            {
                for (var x in parts)
                {
                    if (parts[x].length > 3 || (parts[x].length == 3 && x > 0))
                    {
                        return parts[x];
                    }
                }
            }
        }
        return '';
    }

	$(function(){
	        $('.shield').on('click', function(e){
        e.preventDefault();
                    alert('Site privacy analysis in process of being implemented (and may never get released...)');
            });
	})
    </script><script src="/Risks/assets/js/risksmzr2.js"></script><script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"></script><script>
     WebFont.load({
        google: {
          families: ['Open Sans']
        }
      });
    </script></chapman></pre>
</body>
</html>

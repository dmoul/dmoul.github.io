<!DOCTYPE html>
<html lang="en" itemscope="" itemtype="http://schema.org/WebPage" prefix="og: http://ogp.me/ns#">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>The RISKS Digest Volume 17 Issue 69</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="apple-touch-icon-precomposed" sizes="57x57" href="/Risks/assets/favicons/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/Risks/assets/favicons/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/Risks/assets/favicons/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/Risks/assets/favicons/apple-touch-icon-144x144.png">
<link rel="apple-touch-icon-precomposed" sizes="60x60" href="/Risks/assets/favicons/apple-touch-icon-60x60.png">
<link rel="apple-touch-icon-precomposed" sizes="120x120" href="/Risks/assets/favicons/apple-touch-icon-120x120.png">
<link rel="apple-touch-icon-precomposed" sizes="76x76" href="/Risks/assets/favicons/apple-touch-icon-76x76.png">
<link rel="apple-touch-icon-precomposed" sizes="152x152" href="/Risks/assets/favicons/apple-touch-icon-152x152.png">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-196x196.png" sizes="196x196">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-128.png" sizes="128x128">
<meta name="application-name" content="The Risks Digest">
<meta name="msapplication-TileColor" content="#FFFFFF">
<meta name="msapplication-TileImage" content="/Risks/assets/favicons/mstile-144x144.png">
<meta name="msapplication-square70x70logo" content="/Risks/assets/favicons/mstile-70x70.png">
<meta name="msapplication-square150x150logo" content="/Risks/assets/favicons/mstile-150x150.png">
<meta name="msapplication-wide310x150logo" content="/Risks/assets/favicons/mstile-310x150.png">
<meta name="msapplication-square310x310logo" content="/Risks/assets/favicons/mstile-310x310.png">
<link rel="stylesheet" href="/Risks/assets/css/rlayout.min.css" media="screen">
<link rel="Up" href="/Risks/">
<link rel="Contents" href="/Risks/">
<link rel="Help" href="/Risks/">
<link rel="Home" href="/Risks/">
<link rel="Search" href="/Risks/search">
<link rel="First" href="/Risks/1/1">
<link rel="Last" href="/Risks/latest">
<link rel="Copyright" href="/Risks/info.html#cpr">
<link rel="alternate" href="/rdigest.rdf" type="application/rss+xml" title="RSS">
<link rel="alternate" href="/risksrss1.xml" type="application/rss+xml" title="RSS 1.0">
<link rel="alternate" href="/risksrss2" type="application/rss+xml" title="RSS 2.0">
<link rel="alternate" href="/risksatom.xml" type="application/atom+xml" title="ATOM">
<link rel="alternate" href="/risks.json" type="application/json" title="JSON Feed">
<link rel="alternate" href="/risksgorss1.xml" type="application/rss+xml" title="RSS 1.0 WAP">
<link rel="alternate" href="/risksgorss2" type="application/rss+xml" title="RSS 2.0 WAP">
<link rel="alternate" href="/risksgoatom.xml" type="application/atom+xml" title="ATOM WAP">
<link rel="alternate" href="/risksgo.json" type="application/json" title="JSON Feed">
<link rel="Index" href="/Risks/17/index">
<link rel="Prev" href="/Risks/17/68">
<link rel="Next" href="/Risks/17/70">
<meta name="DC.Creator" content="Peter G. Neumann">
<meta name="DC.Title" content="The RISKS Digest, Volume 17 Issue 69">
<meta name="DC.Language" content="en">
<meta name="DC.Type" content="Text">
<meta name="DC.Format" content="text/html">
<meta property="og:title" content="The RISKS Digest, Volume 17 Issue 69">
<meta property="og:site_name" content="The Risks Digest">
<meta property="og:locale" content="en">
<meta property="og:type" content="website">
<meta name="citation_author" content="Peter G. Neumann">
<meta name="citation_title" content="The RISKS Digest, Volume 17 Issue 69">
<meta name="citation_journal_title" content="The RISKS Digest, Volume 17 Issue 69">
<meta name="DC.Date" content="1996-02-07">
<meta property="og:article:published_time" content="1996-02-07">
<meta name="citation_volume" content="17">
<meta name="citation_issue" content="69">
<meta name="citation_publication_date" content="1996/02/07">
</head>
<body lang="en-GB">
            <nav><div class="btns">
                                                <a href="/Risks/17/68" title="Volume 17 Issue 68" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-left"></i></a>
                                <a href="/Risks/17/index" title="Volume 17 Index" itemprop="relatedLink"><i class="fad fa-fw fa-list"></i></a>
                                                    <a href="/Risks/17/70" title="Volume 17 Issue 70" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-right"></i></a>
                                        <a href="mailto:risks@csl.sri.com" title="Submit an article to RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-envelope"></i></a>
            <a href="mailto:lindsay.marshall@newcastle.ac.uk?subject=Risks+Problem+17.69" title="Report a problem with this issue" itemprop="relatedLink"><i class="fad fa-fw fa-bug"></i></a>
            <a href="/Risks/archive/17/risks-17.69.gz" title="Fetch this issue as compressed plaintext" itemprop="relatedLink"><i class="fad fa-fw fa-cloud-download-alt"></i></a>
            <a href="/Risks/latest" title="The latest issue" itemprop="relatedLink"><i class="fad fa-fw fa-fast-forward"></i></a>
                            <a href="/Risks/" title="Information about RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-info"></i></a>
                                </div>
        <div class="srch">
            <form action="/Risks/search" method="get">
                <label>Search RISKS <input type="text" name="query" placeholder="Query String"></label>
                <button type="submit"><i class="fad fa-fw fa-search"></i></button>
            </form>
        </div>
        <div class="clear"></div>
    </nav><h1 class="cntr" itemprop="name">
<span class="rdigest">The RISKS Digest</span><br>Volume 17 Issue 69</h1>
            <h2 class="cntr">Wednesday, 7th February 1996</h2>
        <h3 class="cntr">Forum on Risks to the Public in Computers and Related Systems</h3>
    <h3 class="cntr">
	<i><a href="//www.acm.org">ACM</a> Committee on Computers and Public Policy,
	<a href="http://www.csl.sri.com/neumann/neumann.html">Peter G. Neumann</a>, moderator</i>
        </h3>

    <h3>Contents</h3>
    

<dl>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj1">REPORT: Minimal Key Lengths for Symmetric Ciphers</a>
</dt>
<dd>
<a href="#subj1.1">Matt Blaze</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj2">RISKS (and lack thereof) of typing credit-card numbers</a>
</dt>
<dd>
<a href="#subj2.1">Olin Sibert</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj3">Over the air: More cellular-phone risks</a>
</dt>
<dd>
<a href="#subj3.1">Bob Frankston</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj4">Subway Difficulties</a>
</dt>
<dd>
<a href="#subj4.1">Mark Neely</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj5">Re: Unintended Missile Launches</a>
</dt>
<dd>
<a href="#subj5.1">Pete McVay</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj6">IEEE Symposium on Security and Privacy</a>
</dt>
<dd>
<a href="#subj6.1">Dale M. Johnson</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="/Risks">ABRIDGED info on RISKS (comp.risks)</a>
</dt>
</dl>
<a name="subj1" href="#subj1" id="subj1"><hr class="main"></a>
<h3>
<a name="subj1.1" href="#subj1.1" id="subj1.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> REPORT: Minimal Key Lengths for Symmetric Ciphers</h3>
<address>Matt Blaze &lt;<a href="mailto:mab@research.att.com">mab@research.att.com</a>&gt;</address>
<i>Tue, 06 Feb 1996 01:59:31 -0500</i>
<p>At the request of the Business Software Alliance (BSA), an ad hoc panel of seven cryptologists and computer scientists met last November to address the question of the minimum key length required to provide adequate security against exhaustive search
in commercial applications of symmetric cryptosystems. We have just completed our report.</p>
<p>We adopted a simple, and somewhat conservative, methodology in an effort to gain a realistic understanding of what size keys might actually be vulnerable in practice. It is common in analysis of key length to give all benefit of the doubt to the
capabilities of the potential attacker and to make very generous assumptions about the technology and resources that might be available to mount an attack. In our analysis, however, we assumed that the attacker would employ only conventional,
commercially-mature technologies and would be limited by budget and time constraints. We used several different technologies to design attack strategies that accommodate the budgets of various hypothetical attackers, from individual ``hackers'' to
well-funded enterprises. Our conclusions, therefore, represent an approximation of an ``upper bound'' on the strength of various size keys; I believe more efficient attacks than those we considered might also be possible and should be taken into account
by the prudent cryptosystem designer.</p>
<p>The abstract of the report follows below.</p>
<p>A PostScript copy of the full text of the report is available in <a href="ftp://ftp.research.att.com/dist/mab/keylength.ps">ftp://ftp.research.att.com/dist/mab/keylength.ps</a> An ASCII version is available in <a href="ftp://ftp.research.att.com/dist/mab/keylength.txt">ftp://ftp.research.att.com/dist/mab/keylength.txt</a></p>
<p>(The report will also likely appear on the BSA's web site shortly).</p>
<address>-matt (speaking only for himself)</address>
=======================================================================<br>
Minimal Key Lengths for Symmetric Ciphers to Provide Adequate Commercial Security
<p>A Report by an Ad Hoc Group of Cryptographers and Computer Scientists</p>
<p>Matt Blaze (1)<br>
Whitfield Diffie (2)<br>
Ronald L. Rivest (3)<br>
Bruce Schneier (4)<br>
Tsutomu Shimomura (5)<br>
Eric Thompson (6)<br>
Michael Wiener (7)</p>
<p>January 1996</p>
<p>ABSTRACT</p>
<p>Encryption plays an essential role in protecting the privacy of electronic information against threats from a variety of potential attackers. In so doing, modern cryptography employs a combination of _conventional_ or _symmetric_ cryptographic systems
for<br>
encrypting data and _public key_ or _asymmetric_ systems for managing the _keys_ used by the symmetric systems. Assessing the strength required of the symmetric cryptographic systems is therefore an essential step in employing cryptography for computer
and communication security.</p>
<p>Technology readily available today (late 1995) makes _brute-force_ attacks against cryptographic systems considered adequate<br>
for the past several years both fast and cheap. General purpose computers can be used, but a much more efficient approach is to employ commercially available _Field Programmable Gate Array (FPGA)_ technology. For attackers prepared to make a higher
initial investment, custom-made, special-purpose chips make such calculations much faster and significantly lower the amortized cost per solution.</p>
<p>As a result, cryptosystems with 40-bit keys offer virtually no protection at this point against brute-force attacks. Even the U.S. Data Encryption Standard with 56-bit keys is increasingly inadequate. As cryptosystems often succumb to `smarter' attacks
than brute-force key search, it is also important to remember that the keylengths discussed here are the minimum needed for security against the computational threats considered.</p>
<p>Fortunately, the cost of very strong encryption is not significantly greater than that of weak encryption. Therefore, to provide adequate protection against the most serious threats --- well-funded commercial enterprises or government intelligence
agencies --- keys used to protect data today should be at least 75 bits long.<br>
To protect information adequately for the next 20 years in the face of expected advances in computing power, keys in newly-deployed systems should be at least 90 bits long.</p>
<ol>
<li>AT&amp;T Research, <a href="mailto:mab@research.att.com">mab@research.att.com</a>
</li>
<li>Sun Microsystems, <a href="mailto:diffie@eng.sun.com">diffie@eng.sun.com</a>
</li>
<li>MIT Laboratory for Computer Science, <a href="mailto:rivest@lcs.mit.edu">rivest@lcs.mit.edu</a>
</li>
<li>Counterpane Systems, <a href="mailto:schneier@counterpane.com">schneier@counterpane.com</a>
</li>
<li>San Diego Supercomputer Center, <a href="mailto:tsutomu@sdsc.edu">tsutomu@sdsc.edu</a>
</li>
<li>Access Data, Inc., <a href="mailto:eric@accessdata.com">eric@accessdata.com</a>
</li>
<li>Bell Northern Research, <a href="mailto:wiener@bnr.ca">wiener@bnr.ca</a>
</li>
</ol>
<a name="subj2" href="#subj2" id="subj2"><hr class="main"></a>
<h3>
<a name="subj2.1" href="#subj2.1" id="subj2.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> RISKS (and lack thereof) of typing credit-card numbers</h3>
<address>Olin Sibert &lt;<a href="mailto:wos@oxford.com">wos@oxford.com</a>&gt;</address>
<i>Sat, 3 Feb 96 19:21:22 EST</i>
<p>Recently, there has been much publicity about a problem inherent in today's personal computers: software on a PC can recognize credit-card numbers as they are typed on the keyboard, with no knowledge of why the number is being typed, what application
is running, etc. The RISK here is that such software could be malicious--for example, it could run invisibly in the background and send credit-card numbers it discovers to its creator--anonymously and untraceably. The publicity came in press interviews
(San Jose Mercury News, 29 January 1996) and in subsequently distributed material from First Virtual Holdings (FV). The problem is characterized by FV as "fatal", as a "discovery", as "undermining every known credit-card encryption mechanism for Internet
commerce", and as having no possible technical defenses or counter-measures.</p>
<p>Is this a RISK? If so, how to characterize it?</p>
<p>The discussion has revolved around four basic claims:</p>
<ol>
<li>Keystrokes are easily captured by a relatively simple keyboard sniffer program.</li>
<li>Typed credit-card numbers are easily recognizable, without need for context or knowledge about user activity,</li>
<li>Malicious software can be easily and tracelessly infiltrated into large numbers of consumer PCs</li>
<li>Credit-card numbers can be returned to a perpetrator using invisible, untraceable, and anonymous means</li>
</ol>
How supportable are these claims? On closer examination, only the first stands up especially well; the other three, though technically possible, are by no means fatal or unavoidable.
<p>In technical terms, there is certainly a RISK. The scenario described in the newspaper article, and elaborated on by Nat Borenstein (FV's Chief Scientist) is technically accurate: malicious programs can transmit information to parties who oughtn't have
it.</p>
<p>This is not news. It has been well understood in the computer security field for, well, about three decades. It is the fundamental threat underlying the security mechanism called Mandatory Access Control. And, I imagine, it's something that makes
computer security and virus researchers lose sleep some nights. Indeed, because of this threat, there are those who say they never run any software they haven't personally studied and compiled themselves (though I've often wondered what they do about
compilers... and microcode).</p>
<p>The language used to describe the threat ("the flaw ... is fatal"), however, is a bit on the hyperbolic side. First of all, the threat is not unique to Internet commerce: it applies to information processing in general. The threat is equally applicable
against numbers that one might enter as account identifiers in a personal finance program, or even against credit-card numbers in a letter written with a word processor (perhaps to inquire about incorrect charges). Such uses are just as vulnerable--one
need never even attempt an electronic purchase to "lose" a credit-card number this way. The advice from FV does state "never type your credit-card number into a computer", but it focuses solely on commerce mechanisms, which is a bit misleading.</p>
<p>Secondly, there ARE effective counter-measures, of both a defensive and an offensive nature, other than giving up on credit-card numbers for electronic commerce. FV characterizes the only two possible solutions as "secure hardware add-ons and the First
Virtual approach", because in the latter, a user is not required to type credit-card number into a PC. These approaches impose certain costs, risks, and benefits that must be weighed sensibly against corresponding attributes of other approaches. Even if
they were the only possible "solutions", they might not be sufficiently cost-effective to be worth using.</p>
<p>Finally, it's important to identify the stakeholders clearly and not to overstate the RISK. Just as one runs certain risks in handing a credit card to a minimum-wage employee, personal computers pose some risks--but who benefits and who bears the costs
are critical to a system analysis.</p>
<p>The first claim (ease of keyboard sniffing) is certainly true; the demonstration program shows that nicely.</p>
<p>The second claim (ease of recognition) is more dubious. Certainly, credit-card numbers typed in directly from a keyboard are recognizable, but is that the only practical way to enter them? Of course not. There are several obvious technical
counter-measures for this aspect of the threat. For example, one could enter part of the number, back up with cursor keys, and enter the rest of the number. Software could request the number following a simple code (e.g., 0=W, 1=S, 2=Z, generated randomly
for each request; a similar approach is used for verifying licensees of much PC game software). Software could display a calculator key-pad for entering the number with mouse clicks. And so on--a little ingenuity goes a long way.</p>
<p>Although these methods may seem a bit clumsy, they need only be used once per credit-card number. That one-time inconvenience would not be an unreasonable burden for users--and data entry errors (which clearly are a risk of such special-purpose
interfaces) would be minimal due to precisely the same properties that make credit-card numbers easily recognizable in the first place. Such counter-measures undermine the "fatal flaw" claim, for none of them require an account-based system like FV's;
neither do they involve secure hardware.</p>
<p>Of course, malicious software could also be created to defeat any of these approaches, just as it could be created to perform the "extremely difficult" task of defrauding FV's multi-step transaction approach. However, any of these counter-measures
removes the most important property of the attack: the ability to recognize credit-card numbers without context. Instead, a significantly more complex directed attack--or, rather, one for each possible application program--is needed to extract the numbers
from a deliberately safeguarded user interface.</p>
<p>There is a related threat that relies on the recognizability attribute: finding credit-card numbers stored, say, as ASCII text in memory, on disk, or in network traffic is no more conceptually difficult than recognizing keystrokes. The same sort of
context-free recognition is straightforward. However, even a light encryption of such data (e.g., XOR) will foil the simple context-free attack, and require that a recognition program understand the semantics of the data it's looking for. The analysis
here applies to such scenarios as well.</p>
<p>The third claim (easy and traceless infiltration) is dubious as well. Truly effective malicious software is DIFFICULT: witness the extremely primitive payloads of most extant PC viruses. Although recognizing the keystrokes may be easy and reliable,
neither the process of installation into arbitrary consumer PCs nor the mechanism for returning the information is likely to be. Most people who have ever installed software on a PC, or who have ever used a PC-based communication mechanism, will recognize
that these activities have considerable potential to generate errors and anomalous events. Traceless infiltration, however, requires that no such events occur.</p>
<p>Although the great thing about malicious software (from the bad guy's point of view) is that it only needs to be written once and after that, any fool can run it, it still has to be written and to work properly. Capturing credit-card numbers when they
are typed as consecutive digits presents an especially easily recognized pattern, so that part of the program's job is simple, but that doesn't affect the compatibility and reliability aspects. Widespread distribution of a credit-card capture program
would likely result in compatibility problems throughout its user community--nothing serious, but quite possibly enough to to discover it in the same manner that other viruses are discovered. It's not at all clear that such a program could become
widespread without being quickly discovered--which argues against "tracelessly".</p>
<p>This hypothetical (as opposed to FV's laboratory demonstration of partial version of such a program) invisible credit-card capture and delivery program is very similar to a traditional virus payload, except that it need not be self-propagating and its
function is more complex (thus, more likely to be detected). It's probably distributed on-line for maximum efficiency, but that could be done with ordinary viruses also. Viruses are bad, and one could even claim that their existence is a "fatal flaw" in
personal computers... but we go on computing anyway.</p>
<p>The fourth claim (easy and traceless reporting) also is dubious, for similar reasons. Although there are many potential schemes for sending information back to the perpetrator, these back-channels are likely to be noticeable, due perhaps to volume,
perhaps to the appearance of unexpected traffic, or perhaps to errors that occur when a particular back-channel is attempted that doesn't work as expected in some user environment. For example, one proposed scheme involves making postings to "test"
newsgroups and encrypting the information in the article's message ID. Technically feasible, yes, but what happens when a user gets an error message about how the PC "Error 07C: Cannot post to misc.test"? If this starts happening on a wide scale, the
malicious software (though probably not its author) will soon be discovered.</p>
<p>Finally, it's important to recognize what it might mean for a counter-measure to be called successful. If "successful" means apprehending the criminal perpetrator who created the malicious software, well, that's certainly hard. However, if "successful"
means protecting individual consumer credit-card accounts and minimizing the cost to the global financial system, that's much easier. An attack might be detected by noticing anomalies; prevented (offensively) through something like virus-removal
technology; or prevented (defensively) through guarded data entry schemes. Although none of these mean that the perpetrator can be found, they do mean that the attack is foiled--and that financial loss is minimized.</p>
<p>These attacks are certainly technically possible, and worth taking some general counter-measures against. It seems unlikely, however, that they would bankrupt either consumers or financial institutions, or that they would become widespread before
specific counter-measures (along the lines of anti-virus scanners) were available.</p>
<p>One general problem is worth noting: if such an attack IS perpetrated, tracing perpetrators is damned difficult. However, the propensity of criminals to talk about their activities, to keep diaries, and to get caught doing other criminal (and often
stupid) things at least offers some possibilities. I'm actually more worried about lone attackers than about a large-scale organized assault by criminal organizations. Hostile intelligence services (or militaries) are also, to my mind, a bigger threat.
For individuals, the economic incentive for credit-card number theft is, to be sure, greater than for simple virus distribution, but profiting from stolen card numbers is fairly risky and difficult on a large scale--one really needs a retail outlet for
the information.</p>
<p>Knowing all this, it would clearly be prudent (A) to design and use safeguarded user interfaces and (B) to bring this threat into the scope of things that concern developers of virus counter-measures. But abandon encrypted credit-card numbers as any
part of an Internet commerce scheme? That seems like an over-reaction.</p>
<p>The RISK here is one of assuming that a specific technical vulnerability translates directly into a system-wide problem of equal severity, and recourse is inherently impossible. Over-stating the threat can be just as dangerous as ignoring it.</p>
<address>Olin Sibert Oxford Systems, Inc.</address>
<a name="subj3" href="#subj3" id="subj3"><hr class="main"></a>
<h3>
<a name="subj3.1" href="#subj3.1" id="subj3.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Over the air: More cellular-phone risks</h3>
<address>&lt;<a href="mailto:Bob_Frankston@frankston.com">Bob_Frankston@frankston.com</a>&gt;</address>
<i>Mon, 5 Feb 1996 13:00 -0500</i>
<p>I was checking my cellular phone account balance using a cellular phone. They offered a payment option which I took. Luckily I miskeyed it because as I sent it I realized that not only had my tones gone out in the clear but they also read it back in
case the eavesdroppers weren't sophisticated enough to decode the tones.</p>
<p><a name="subj4" href="#subj4" id="subj4"><hr class="main"></a></p>
<h3>
<a name="subj4.1" href="#subj4.1" id="subj4.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Subway Difficulties</h3>
<address>Mark Neely &lt;<a href="mailto:accessnt@ozemail.com.au">accessnt@ozemail.com.au</a>&gt;</address>
<i>Tue, 06 Feb 1996 17:12:23 +1000</i>
<p>This appeared in the latest Educom...</p>
<p>"EVERYONE REMAIN CALM"<br>
The Denver-Rocky Mountain News reports that management at the new $5-billion Denver airport forgot to install an intercom system for the subways that trundle passengers from concourse to concourse, so when the computer controlling the subways broke down,
there was no way to communicate with the trapped passengers. The city has now rectified the situation by purchasing six electronic bullhorns. (Telecommunications Policy Report 28 Jan 96 p10)</p>
<address>Mark Neely - <a href="mailto:accessnt@ozemail.com.au">accessnt@ozemail.com.au</a> / <a href="mailto:mneely@c031.aone.net.au">mneely@c031.aone.net.au</a> Lawyer, Professional Cynic, Author: Australian Beginner's Guide to the Internet</address>
<blockquote><i>[Also noted by <a href="mailto:WYNN@AppleLink.Apple.COM">WYNN@AppleLink.Apple.COM</a> (Wynn, Eleanor,VCA). Now we need to populate the subways with electronic bulls. PGN]</i></blockquote>
<a name="subj5" href="#subj5" id="subj5"><hr class="main"></a>
<h3>
<a name="subj5.1" href="#subj5.1" id="subj5.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Re: Unintended Missile Launches (Shafer, <a href="/Risks/17/67">RISKS-17.67</a>; Martin, 17.68)</h3>
<address>Pete &lt;<a href="mailto:74722.2457@compuserve.com">74722.2457@compuserve.com</a>&gt;</address>
<i>07 Feb 96 11:18:19 EST</i>
<p>The Forrestal missile launching was an unintended launch, but IMHO, it was more of a training error than a hardware failure.</p>
<p>At the time of the incident, I was the aircraft maintenance officer on the USS INDEPENDENCE (CVA-62), the sister ship of the FORRESTAL. The FORRESTAL had just arrived in the waters off Viet Nam when the "incident" (which killed in excess of 100 men--I
don't remember exactly how many) occurred. The FORRESTAL had just come from an eight-month overhaul period, and her crew was inexperienced. Navy ships are required to undergo proficiency inspections, called INSERVs, after long periods of inactivity. The
INDEPENDENCE had given FORRESTAL her INSERV, and she had flunked. This was NOT a reflection on the crew, but rather on the fact that they needed more training. The admiral in charge of the INSERV inspection, however, overrode the recommendation of his
staff and certified the FORRESTAL as ready for action. The reason given was that the Navy desperately needed the FORRESTAL on station in the Gulf.</p>
<p>A flight deck during flight ops is one of the most hazardous places imaginable. Besides planes taking off or landing, planes and ammunition are being moved around, refueling and defueling is occurring, maintenance vehicles and equipment ("yellow gear")
is moving, testing, and/or starting aircraft, and other operations are going on. This is all in a space only one-tenth the size of a land-based airfield. Flight deck personnel need eyes in the back of their head and a sixth sense of where everything is,
and must know their jobs instinctively. The FORRESTAL crew was so green that during the inspection, the INDEPENDENCE's flight deck officer left the flight deck and refused to return, considering it too dangerous.</p>
<p>I don't recall the details of the actual incident, save that it involved a plane that had been improperly loaded and armed released a missile at an F-4 that was ready for takeoff on catapult #1 (on the port side forward). Since fuel and ammunition had
been improperly placed on the deck, this quickly touched off explosions and fires that ran the length of the deck. I do clearly recall that the reason for the accidental launch was not due to equipment failure: it was caused by aircrew error in both
attaching and arming the missiles. (Consider the problem of designing a system that must NOT work until it's ready, and then must not FAIL to work.)</p>
<p>The risk, in other words, was improper training in a complex and hazardous environment. I would hope that the Navy (and other organizations) would take a lesson from this.</p>
<address>Pete McVay, <a href="mailto:pmcvay@usa1.com">pmcvay@usa1.com</a>
</address>
<a name="subj6" href="#subj6" id="subj6"><hr class="main"></a>
<h3>
<a name="subj6.1" href="#subj6.1" id="subj6.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> IEEE Symposium on Security and Privacy</h3>
<address>"Dale M. Johnson" &lt;<a href="mailto:dmj@linus.mitre.org">dmj@linus.mitre.org</a>&gt;</address>
<i>Thu, 01 Feb 1996 16:17:44 -0500</i>
<pre>
1996 IEEE SYMPOSIUM ON SECURITY AND PRIVACY                    _/_/
May 6-8, 1996                                                _/_/    _/_/_/
The Claremont Resort,                                           _/    _/
Oakland, California                                       _/   _/
_/_/
Sponsored by the                                                  _/_/_/
IEEE Technical Committee on Security and Privacy                 _/   _/
In cooperation with the                                         _/   _/
International Association of Cryptologic Research              _/_/_/
_/
Symposium Committee                                          _/
Dale M. Johnson, General Chair                                    _/_/_/  _/_/
Stephen Kent, Vice Chair                                        _/   _/ _/
John McHugh, Program Co-Chair                                  _/   _/ _/
George W. Dinolt, Program Co-Chair                             _/_/_/ _/_/_/
_/ _/   _/
PRELIMINARY PROGRAM                      _/ _/   _/
Subject to Change                      _/   _/_/
<br>
MONDAY, MAY 6
<br>
08:30-09:00  WELCOMING REMARKS:  Dale Johnson and John McHugh
<br>
09:00-10:30  PANEL:  Object Management Group CORBA Security Standard<br>
Moderator:  Terry Benzel
Participants:  TBA
<br>
10:30-11:00  BREAK
<br>
11:00-12:00  COVERT CHANNELS
<br>
An Analysis of the Timed Z-Channel
Ira S. Moskowitz, Steven J. Greenwald, Myong H. Kang
<br>
Defining Noninterference in the Temporal Logic of Actions
Todd Fine
<br>
12:00-13:30  LUNCH
<br>
13:30-15:00  PANEL:  Goals for Computer Security Education<br>
Cynthia Irvine, Chair
Leslie Chalmers
Karl Levitt
Steven F. Barnett
Jim Schindler
Roger R. Schell
<br>
15:00-15:30  BREAK
<br>
15:30-17:00  FIVE-MINUTE RESEARCH TALKS SESSION
<br>
Submissions in the form of one-page ASCII abstracts
due by e-mail to <a href="mailto:mchugh@cs.pdx.edu">mchugh@cs.pdx.edu</a> no later
than 2 April 1996. See <a href="http://www.cs.pdx.edu/SP96/">http://www.cs.pdx.edu/SP96/</a>
for more information.
Abstracts to be distributed at the conference.
<br>
18:00-19:30  RECEPTION<br><br>
TUESDAY, MAY 7
<br>
09:00-10:30  DOMAIN SPECIFIC SECURITY
<br>
Security for Medical Information Systems
Ross Anderson
<br>
Discussion
Discussants TBA
<br>
10:30-11:00  BREAK
<br>
11:00-12:00  PROTOCOLS
<br>
Entity Authentication
Dieter Gollmann
<br>
A Fair Non-repudiation Protocol
Jianying Zhou, Dieter Gollmann
<br>
Limitations on Design Principles for Public Key Protocols
Paul Syverson
<br>
12:00-13:30  LUNCH
<br>
13:30-15:00  DATABASES
<br>
Ensuring Atomicity of Multilevel Transactions
Paul Ammann, Sushil Jajodia, Indrakshi Ray
<br>
View-Based Access Control with High Assurance
Xiaolei Qian
<br>
Supporting Multiple Access Control Policies in Database Systems
Elisa Bertino, Sushil Jajodia, Pierangela Samarati
<br>
15:00-15:30  BREAK
<br>
15:30-17:00  BIOLOGICALLY INSPIRED TOPICS IN COMPUTER SECURITY
<br>
An Immunological Approach to Change Detection: Algorithms,
Analysis, and Implications
Patrik D'Haeseleer, Stephanie Forrest, Paul Helman
<br>
A Sense of Self for UNIX Processes
Stephanie Forrest, Steven A. Hofmeyr, Anil Somayaji,
Thomas A. Longstaff
<br>
Cryptovirology: Extortion Based Security Threats and Countermeasures
Adam Young, Moti Yung
<br>
17:30-19:30  TECHNICAL COMMITTEE MEETING<br><br>
WEDNESDAY, MAY 8
<br>
09:00-10:30  MODELING
<br>
A Security Model of Dynamic Labeling Providing a Tiered Approach to
Verification
Simon Foley, Li Gong, Xiaolei Qian
<br>
A Communication Agreement Framework of Access Control
Martin Roscheisen, Terry Winograd
<br>
Decentralized Trust Management
Matt Blaze, Joan Feigenbaum, Jack Lacy
<br>
Security Properties and CSP
Steve Schneider
<br>
10:30 11:00  BREAK
<br>
11:00 12:30  NETWORKS
<br>
Security Flaws in the HotJava Web Browser
Drew Dean, Dan S. Wallach
<br>
On Two Proposals for On-line Credit-card Payments using Open
Networks: Problems and Solutions
Wenbo Man
<br>
Secure Network Objects
Leendert van Doorn, Martin Abadi, Mike Burrows, Edward Wobber
<br>
Run-Time Security Evaluation (RTSE) for Distributed Applications
Cristina Serban, B. McMillin
<br>
12:30 12:45  CONCLUDING REMARKS
<br>
12:45        SYMPOSIUM ADJOURNS
<br>
&gt;&gt;&gt;&gt;SORRY, NO REGISTRATIONS BY E-MAIL.  NO REFUNDS.&lt;&lt;&lt;&lt;
</pre>
<blockquote><i>[But PLEASE send Dale an E-mail message requesting the full registration packet, which can be e-mailed to you. PGN]</i></blockquote>

        <nav><div class="btns">
                                                <a href="/Risks/17/68" title="Volume 17 Issue 68" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-left"></i></a>
                                <a href="/Risks/17/index" title="Volume 17 Index" itemprop="relatedLink"><i class="fad fa-fw fa-list"></i></a>
                                                    <a href="/Risks/17/70" title="Volume 17 Issue 70" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-right"></i></a>
                                        <a href="mailto:risks@csl.sri.com" title="Submit an article to RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-envelope"></i></a>
            <a href="mailto:lindsay.marshall@newcastle.ac.uk?subject=Risks+Problem+17.69" title="Report a problem with this issue" itemprop="relatedLink"><i class="fad fa-fw fa-bug"></i></a>
            <a href="/Risks/archive/17/risks-17.69.gz" title="Fetch this issue as compressed plaintext" itemprop="relatedLink"><i class="fad fa-fw fa-cloud-download-alt"></i></a>
            <a href="/Risks/latest" title="The latest issue" itemprop="relatedLink"><i class="fad fa-fw fa-fast-forward"></i></a>
                            <a href="/Risks/" title="Information about RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-info"></i></a>
                                </div>
        <div class="srch">
            <form action="/Risks/search" method="get">
                <label>Search RISKS <input type="text" name="query" placeholder="Query String"></label>
                <button type="submit"><i class="fad fa-fw fa-search"></i></button>
            </form>
        </div>
        <div class="clear"></div>
    </nav><p class="problems">Please report problems with the web pages to <a href="mailto:lindsay.marshall@ncl.ac.uk?subject=Problem+with+RISKS+17.69">the maintainer</a></p>

    <div id="totop">
        <i class="fas fa-chevron-up"></i>Top
    </div>

    <script src="https://kit.fontawesome.com/f38fd5f4bf.js" crossorigin="anonymous"></script><script src="https://code.jquery.com/jquery-3.5.1.min.js"></script><script>
	var base = '/Risks';

	    function hostname(url)
    {
        var match = url.match(/:\/\/(www[0-9]?\.)?(.[^/:]+)/i);
        return match != null && match.length > 2 && typeof match[2] === 'string' && match[2].length > 0 ? match[2] : null;
    }

    function domain(url) {
        var host = hostname(url);
        
        if (host != null)
        {
            var parts = host.toLowerCase().split('.').reverse();
            
            if (parts != null && parts.length > 1)
            {
                for (var x in parts)
                {
                    if (parts[x].length > 3 || (parts[x].length == 3 && x > 0))
                    {
                        return parts[x];
                    }
                }
            }
        }
        return '';
    }

	$(function(){
	        $('.shield').on('click', function(e){
        e.preventDefault();
                    alert('Site privacy analysis in process of being implemented (and may never get released...)');
            });
	})
    </script><script src="/Risks/assets/js/risksmzr2.js"></script><script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"></script><script>
     WebFont.load({
        google: {
          families: ['Open Sans']
        }
      });
    </script>
</body>
</html>

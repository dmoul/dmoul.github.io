<!DOCTYPE html>
<html lang="en" itemscope="" itemtype="http://schema.org/WebPage" prefix="og: http://ogp.me/ns#">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>The RISKS Digest Volume 17 Issue 51</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="apple-touch-icon-precomposed" sizes="57x57" href="/Risks/assets/favicons/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/Risks/assets/favicons/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/Risks/assets/favicons/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/Risks/assets/favicons/apple-touch-icon-144x144.png">
<link rel="apple-touch-icon-precomposed" sizes="60x60" href="/Risks/assets/favicons/apple-touch-icon-60x60.png">
<link rel="apple-touch-icon-precomposed" sizes="120x120" href="/Risks/assets/favicons/apple-touch-icon-120x120.png">
<link rel="apple-touch-icon-precomposed" sizes="76x76" href="/Risks/assets/favicons/apple-touch-icon-76x76.png">
<link rel="apple-touch-icon-precomposed" sizes="152x152" href="/Risks/assets/favicons/apple-touch-icon-152x152.png">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-196x196.png" sizes="196x196">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/Risks/assets/favicons/favicon-128.png" sizes="128x128">
<meta name="application-name" content="The Risks Digest">
<meta name="msapplication-TileColor" content="#FFFFFF">
<meta name="msapplication-TileImage" content="/Risks/assets/favicons/mstile-144x144.png">
<meta name="msapplication-square70x70logo" content="/Risks/assets/favicons/mstile-70x70.png">
<meta name="msapplication-square150x150logo" content="/Risks/assets/favicons/mstile-150x150.png">
<meta name="msapplication-wide310x150logo" content="/Risks/assets/favicons/mstile-310x150.png">
<meta name="msapplication-square310x310logo" content="/Risks/assets/favicons/mstile-310x310.png">
<link rel="stylesheet" href="/Risks/assets/css/rlayout.min.css" media="screen">
<link rel="Up" href="/Risks/">
<link rel="Contents" href="/Risks/">
<link rel="Help" href="/Risks/">
<link rel="Home" href="/Risks/">
<link rel="Search" href="/Risks/search">
<link rel="First" href="/Risks/1/1">
<link rel="Last" href="/Risks/latest">
<link rel="Copyright" href="/Risks/info.html#cpr">
<link rel="alternate" href="/rdigest.rdf" type="application/rss+xml" title="RSS">
<link rel="alternate" href="/risksrss1.xml" type="application/rss+xml" title="RSS 1.0">
<link rel="alternate" href="/risksrss2" type="application/rss+xml" title="RSS 2.0">
<link rel="alternate" href="/risksatom.xml" type="application/atom+xml" title="ATOM">
<link rel="alternate" href="/risks.json" type="application/json" title="JSON Feed">
<link rel="alternate" href="/risksgorss1.xml" type="application/rss+xml" title="RSS 1.0 WAP">
<link rel="alternate" href="/risksgorss2" type="application/rss+xml" title="RSS 2.0 WAP">
<link rel="alternate" href="/risksgoatom.xml" type="application/atom+xml" title="ATOM WAP">
<link rel="alternate" href="/risksgo.json" type="application/json" title="JSON Feed">
<link rel="Index" href="/Risks/17/index">
<link rel="Prev" href="/Risks/17/50">
<link rel="Next" href="/Risks/17/52">
<meta name="DC.Creator" content="Peter G. Neumann">
<meta name="DC.Title" content="The RISKS Digest, Volume 17 Issue 51">
<meta name="DC.Language" content="en">
<meta name="DC.Type" content="Text">
<meta name="DC.Format" content="text/html">
<meta property="og:title" content="The RISKS Digest, Volume 17 Issue 51">
<meta property="og:site_name" content="The Risks Digest">
<meta property="og:locale" content="en">
<meta property="og:type" content="website">
<meta name="citation_author" content="Peter G. Neumann">
<meta name="citation_title" content="The RISKS Digest, Volume 17 Issue 51">
<meta name="citation_journal_title" content="The RISKS Digest, Volume 17 Issue 51">
<meta name="DC.Date" content="1995-12-04">
<meta property="og:article:published_time" content="1995-12-04">
<meta name="citation_volume" content="17">
<meta name="citation_issue" content="51">
<meta name="citation_publication_date" content="1995/12/04">
</head>
<body lang="en-GB">
            <nav><div class="btns">
                                                <a href="/Risks/17/50" title="Volume 17 Issue 50" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-left"></i></a>
                                <a href="/Risks/17/index" title="Volume 17 Index" itemprop="relatedLink"><i class="fad fa-fw fa-list"></i></a>
                                                    <a href="/Risks/17/52" title="Volume 17 Issue 52" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-right"></i></a>
                                        <a href="mailto:risks@csl.sri.com" title="Submit an article to RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-envelope"></i></a>
            <a href="mailto:lindsay.marshall@newcastle.ac.uk?subject=Risks+Problem+17.51" title="Report a problem with this issue" itemprop="relatedLink"><i class="fad fa-fw fa-bug"></i></a>
            <a href="/Risks/archive/17/risks-17.51.gz" title="Fetch this issue as compressed plaintext" itemprop="relatedLink"><i class="fad fa-fw fa-cloud-download-alt"></i></a>
            <a href="/Risks/latest" title="The latest issue" itemprop="relatedLink"><i class="fad fa-fw fa-fast-forward"></i></a>
                            <a href="/Risks/" title="Information about RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-info"></i></a>
                                </div>
        <div class="srch">
            <form action="/Risks/search" method="get">
                <label>Search RISKS <input type="text" name="query" placeholder="Query String"></label>
                <button type="submit"><i class="fad fa-fw fa-search"></i></button>
            </form>
        </div>
        <div class="clear"></div>
    </nav><h1 class="cntr" itemprop="name">
<span class="rdigest">The RISKS Digest</span><br>Volume 17 Issue 51</h1>
            <h2 class="cntr">Monday, 4th December 1995</h2>
        <h3 class="cntr">Forum on Risks to the Public in Computers and Related Systems</h3>
    <h3 class="cntr">
	<i><a href="//www.acm.org">ACM</a> Committee on Computers and Public Policy,
	<a href="http://www.csl.sri.com/neumann/neumann.html">Peter G. Neumann</a>, moderator</i>
        </h3>

    <h3>Contents</h3>
    

<dl>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj1">Costs of 1999-&gt;2000 date fix</a>
</dt>
<dd>
<a href="#subj1.1">James K. Huggins</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj2">CD-ROM that hoses your hard drive</a>
</dt>
<dd>
<a href="#subj2.1">Stanton McCandlish</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj3">Re: Sex, Lies and Backup Disks</a>
</dt>
<dd>
<a href="#subj3.1">Tom Wicklund</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj4">How's your spell?</a>
</dt>
<dd>
<a href="#subj4.1">Peter Ladkin</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj5">Re: Spelling Correctors</a>
</dt>
<dd>
<a href="#subj5.1">Edward Reid</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj6">New software that is just too clever</a>
</dt>
<dd>
<a href="#subj6.1">Malcolm Farmer</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj7">Ambiguous abbreviation: what does "NCSA" mean?</a>
</dt>
<dd>
<a href="#subj7.1">Jonathan Thornburg</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj8">Industrial espionage 0.5%</a>
</dt>
<dd>
<a href="#subj8.1">David Lifton</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="#subj9">Re: risks in medical equipment</a>
</dt>
<dd>
<a href="#subj9.1">Pete Mellor</a><br><a href="#subj9.2">Bridget Moorman</a><br><a href="#subj9.3">Erik Hollnagel</a><br><a href="#subj9.4">Jay Harrell</a><br><a href="#subj9.5">Kenneth Albanowski</a><br><a href="#subj9.6">Steve Branam</a><br><a href="#subj9.7">Robert J Horn</a><br><a href="#subj9.8">Rochelle Grober</a><br>
</dd>
<dt>
<img src="/Images/redball.gif" alt="o" width="14" height="14"><a href="/Risks">ABRIDGED info on RISKS (comp.risks)</a>
</dt>
</dl>
<a name="subj1" href="#subj1" id="subj1"><hr class="main"></a>
<h3>
<a name="subj1.1" href="#subj1.1" id="subj1.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Costs of 1999-&gt;2000 date fix</h3>
<address>"James K. Huggins" &lt;<a href="mailto:huggins@eecs.umich.edu">huggins@eecs.umich.edu</a>&gt;</address>
<i>Mon, 4 Dec 1995 13:50:13 -0500 (EST)</i>
<p>The Sunday, 3 December 1995 issue of the Detroit News included an article discussing the projected costs of fixing current programs to correctly handle dates in the year 2000.</p>
<p>This discussion has appeared many times in RISKS, but the article provides some interesting numbers (both actual and projected).</p>
<p>Consumers Power Co. (a Michigan-based electrical utility) began the conversion process two years ago and estimates it will take $20-45M (US) to convert their 350 computer systems. A spokesman for Consumers Power says that the problem for them is quite
serious; if not fixed, it could lead to denial of service for its customers. Blue Cross (a health-care provider), which processes 100 million medical claims per year, has budgeted $3M for this year alone to begin converting its systems.</p>
<p>The article gives a few other estimates, claiming that the average Fortune 500 company will spend $100M to convert their own systems. Worldwide, the<br>
cost is estimated at $300-600M.</p>
<p>Bill Schoen, a computer programmer from Ford who (the article states) was the first to write about the 2000 problem in 1983, says he contacted every Fortune 500 company about the problem at that time, but few were interested. "The people that were in
positions of power then were going to be retired long before this problem kicked in. They didn't care about a mess they weren't going to be around to clean up."</p>
<address>--Jim Huggins, University of Michigan (<a href="mailto:huggins@umich.edu">huggins@umich.edu</a>)</address>
<blockquote><i>[This problem gives new meaning to "going out on a date" (which many systems will do on 1/1/00). PGN]</i></blockquote>
<a name="subj2" href="#subj2" id="subj2"><hr class="main"></a>
<h3>
<a name="subj2.1" href="#subj2.1" id="subj2.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> CD-ROM that hoses your hard drive</h3>
<address>Stanton McCandlish &lt;<a href="mailto:mech@eff.org">mech@eff.org</a>&gt;</address>
<i>Mon, 4 Dec 1995 17:03:35 -0800 (PST)</i>
<p>[From Cable Regulation Digest]</p>
<p>More powerful than a defective Pentium chip, it's the Intel CD-ROM! Intel developed a press kit that really has impact on reporters — it cripples their computers. In touting their cable modems at the Western Show, Intel execs distributed a press kit
with a CD-ROM demo of some of their modem products. Unfortunately, cranking it up will change those pesky configuration specs on your hard drive, leaving you unable to run other programs. Staffers hurriedly posted signs in the press room warning that the
CD "will seriously damage your computer system. Please discard immediately."</p>
<address>Stanton McCandlish, Electronic Frontier Foundation<br><a href="mailto:mech@eff.org">mech@eff.org</a> <a href="http://www.eff.org/">http://www.eff.org/</a>"</address>
<a name="subj3" href="#subj3" id="subj3"><hr class="main"></a>
<h3>
<a name="subj3.1" href="#subj3.1" id="subj3.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Re: Sex, Lies and Backup Disks</h3>
<address>Tom Wicklund &lt;<a href="mailto:wicklund@Intellistor.COM">wicklund@Intellistor.COM</a>&gt;</address>
<i>4 Dec 1995 17:29:30 -0700</i>
<p>While it's well known that deleting a file from a disk doesn't really remove the contents, I'm not sure if even a disk erasure program will get rid of the file.</p>
<p>I remember a few years after the Nixon tapes and infamous erasure of some chunk of the tape (20 minutes?). I was talking to somebody working at a research lab who said that according to their magnetic recording expert the contents could have been
recovered even if they were simply erased — enough signal would remain if you really wanted to get the information back.</p>
<p>The best advice if you're giving a computer disk to somebody else is to use a new disk and don't use any sort of copy software which might get the unused portion of the last sector of a file.</p>
<p><a name="subj4" href="#subj4" id="subj4"><hr class="main"></a></p>
<h3>
<a name="subj4.1" href="#subj4.1" id="subj4.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> How's your spell?</h3>
<address>&lt;<a href="mailto:ladkin@techfak.uni-bielefeld.de">ladkin@techfak.uni-bielefeld.de</a>&gt;</address>
<i>Mon, 4 Dec 1995 10:27:53 +0100</i>
<p>&gt; spellchecker -&gt; spell checker</p>
<p>Although I knew there was a lot of fairy dust in Silicon Valley, I didn't imagine it had been automated yet. A spell checker checks spells. I don't think that's what was meant. Something that checks spellings is either a `spelling checker' or, in the
common Valley contraction, a `spellchecker'.</p>
<blockquote><i>[And RISKS has been checking for many a spell. PGN]</i></blockquote>
<a name="subj5" href="#subj5" id="subj5"><hr class="main"></a>
<h3>
<a name="subj5.1" href="#subj5.1" id="subj5.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Re: Spelling Correctors</h3>
<address>Edward Reid &lt;<a href="mailto:ed@titipu.resun.com">ed@titipu.resun.com</a>&gt;</address>
<i>Sun, 3 Dec 95 09:20:18 -0500</i>
<p>Spelling deviations have always been funny. The little column-end snippets in The New Yorker are often based on spelling deviations, and have been since long before computers were involved. An old favorite of mine substituted Datsun for dachshund.</p>
<p>The exact nature of the errors has changed, since computers check spelling differently from the human mind. The old deviations, like the example above, were often based on phonetic similarity whereas the new deviations are related to digital
manipulation of the letters. But aren't we just continuing our fascination with spelling rather than discussing any risk of computer use?</p>
<p>Our society is obsessed with "correct" spelling. This obsession didn't exist 400 years ago. If an writer changed a spelling, well, that was a new usage. I've heard it claimed that Shakespeare spelled his own name more different ways than anyone else in
history.</p>
<p>I pick up spelling easily. This is a blessing and a curse.</p>
<p>In the current environment, where "correct" spelling is considered important, I can produce a document with no spelling deviations beyond an occasional typo. But when I read a document that is well written but marred by significant deviations from
standard spelling, my mind is drawn to the spelling to the detriment of my ability to absorb the content. At such times, I often wish that I and others had a more accepting attitude toward spelling deviations.</p>
<p>Perhaps the risk is that computers have given us another basketful of examples to feed an unhealthy fascination with spelling.</p>
<address>Edward Reid</address>
<blockquote><i>[Similar items have appeared in RISKS in the past. However, this isn clearly a serious risk, and deserves repeating for new readers. PGN]</i></blockquote>
<a name="subj6" href="#subj6" id="subj6"><hr class="main"></a>
<h3>
<a name="subj6.1" href="#subj6.1" id="subj6.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> New software that is just too clever</h3>
<address>Malcolm Farmer &lt;<a href="mailto:farmermj@bham.ac.uk">farmermj@bham.ac.uk</a>&gt;</address>
<i>Mon, 04 Dec 95 13:10:32 PST</i>
<p>Jeffrey Sherman (<a href="/Risks/17/49">RISKS-17.49</a>) mentioned quirks of WordPerfect 6.1 being too clever. Here's something we found a few weeks ago:</p>
<p>A colleague was trying to prepare a table for publication, listing locations of particular parts of a gene in a long sequence. He would type something like '179-285' into the table boxes, only to find when he tabbed along to the next box, that WP would
replace it with -106. He couldn't find any way to persuade WordPerfect to stop treating the table box as a spreadsheet entry, and being in a hurry to get the paper completed, wound up typing these entries in the form '179 to 285', which finally persuaded
WP to leave them alone.</p>
<p><a name="subj7" href="#subj7" id="subj7"><hr class="main"></a></p>
<h3>
<a name="subj7.1" href="#subj7.1" id="subj7.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Ambiguous abbreviation: what does "NCSA" mean?</h3>
<address>Jonathan Thornburg &lt;<a href="mailto:thornbur@black-hole.physics.ubc.ca">thornbur@black-hole.physics.ubc.ca</a>&gt;</address>
<i>Tue, 31 Oct 1995 07:59:25 -0800</i>
<p>The posting on "NCSA FireWallCon '96" in <a href="/Risks/17/42">RISKS v17 n42</a> unintentionally illustrates another (in)famous risk: ambiguous abbreviations.</p>
<p>When reading this item, I, and I suspect many others, assumed that "NCSA" referred to the US National Center for Supercomputing Applications, well-known for (among many other things) such widely-used software as NCSA Telnet for PCs and more recently
NCSA Mosaic. Since NCSA have been a major internet site for some years, their sponsoring a firewalls convention seemed quite plausible. I thought the various *.ncsa.com internet addresses given were a bit odd, since NCSA always used to have
*.ncsa.uiuc.edu addresses, but I didn't pay too much attention to this.</p>
<p>It was only when reading the _last_line_ (the poster's signature, which in fact our moderator usually trims) of the RISKS item that I discovered that "NCSA" actually referred to the (presumably US) National Computer Security Association!</p>
<p>The lessons to be learned? Well, there are about 450K possible 4-letter sequences, but a simple "birthday paradox" calculation shows there's a 50% chance of duplication if we randomly choose 800 (!) of them. (The nonrandom letter-frequency distribution
of real-world abbreviations just makes things worse.) So this sort of "name abbreviation ambiguity" is going to happen more and more often. About all we can do is to spell out key abbreviations in the lead paragraphs of our postings.</p>
<address>- Jonathan Thornburg<br>
U of British Columbia / Physics Dept / &lt;<a href="mailto:thornbur@theory.physics.ubc.ca">thornbur@theory.physics.ubc.ca</a>&gt;</address>
<a name="subj8" href="#subj8" id="subj8"><hr class="main"></a>
<h3>
<a name="subj8.1" href="#subj8.1" id="subj8.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Industrial espionage 0.5%</h3>
<address>David Lifton &lt;<a href="mailto:David@lifton.demon.co.uk">David@lifton.demon.co.uk</a>&gt;</address>
<i>Sun, 3 Dec 1995 13:43:29 +0000</i>
<p>A snippet from the magazine "Information Management and Computer Security" provides the following survey (orig. source: Survive):</p>
<p>Survey of Disaster Causes: Europe and USA 1980 - 1991</p>
<p>1. Software problems 14.8%<br>
2. Fraud 11.1%<br>
3. Malicious Damage 10.2%<br>
...<br>
20. Electromagnetic interference 1.3%<br>
23. Earthquake 0.8%<br>
26. Industrial espionage 0.5%</p>
<p>Does anyone know of any *published* industrial espionage (information warfare) cases?</p>
<p>Another article by John Bates (Australia, KPMG 1995 Fraud Survey) states that 7th on the scale of most prevalent fraud by management was that 6% of information theft was perpetrated by management.</p>
<address>
<a href="mailto:David@lifton.demon.co.uk">David@lifton.demon.co.uk</a> Lifton Research</address>
<blockquote><i>[There are quite a few *unpublished* ones. PGN]</i></blockquote>
<a name="subj9" href="#subj9" id="subj9"><hr class="main"></a>
<h3>
<a name="subj9.1" href="#subj9.1" id="subj9.1"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Re: risks in medical equipment (Harvey, <a href="/Risks/17/50">RISKS-17.50</a>)</h3>
<address>Pete Mellor &lt;<a href="mailto:pm@csr.city.ac.uk">pm@csr.city.ac.uk</a>&gt;</address>
<i>Sun, 3 Dec 95 16:21:59 GMT</i>
<p>&gt; ... because some technologies are socially defined as 'male' ...</p>
<p>Fortunately for the RISKS community, my partner has discovered the real reason for people being intimidated by technology. She has observed that, despite the fact that I am a computer professional, I seem to be totally intimidated by digital technology
in certain contexts. Specifically, I am totally unable to recall which programs to use for different types of clothes when putting a load of washing into the automatic washing machine.</p>
<p>She has thought long and hard about this and has concluded that the difference is that most kitchen equipment comes in nice attractive light colours whereas technologies that are socially defined as 'male' often come in dark coloured or black
boxes.</p>
<p>She has concluded that the simplest solution to enable me to do a load of washing on my own is to paint the washing machine black.</p>
<p>Unfortunately, the correlation is not perfect. For example, I can never remember how to programme the (black) video recorder to record a TV show at a particular time when we are out, either.</p>
<p>A more in-depth study is needed. If the European Union could provide me with funds for the purchase of a lot of advanced domestic gadgets in a variety of attractive colours, I will undertake the necessary controlled experiments.</p>
<address>Peter Mellor, Centre for Software Reliability, City University, Northampton Square, London EC1V 0HB, UK +44 (171) 477-8422 <a href="mailto:p.mellor@csr.city.ac.uk">p.mellor@csr.city.ac.uk</a>
</address>
<hr>
<h3>
<a name="subj9.2" href="#subj9.2" id="subj9.2"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Re: Alarm and alarm-silencing risks in medical equipment</h3>
<address>Bridget Moorman &lt;<a href="mailto:moormanb@bigdog.engr.arizona.edu">moormanb@bigdog.engr.arizona.edu</a>&gt;</address>
<i>Mon, 4 Dec 1995 11:28:32 -0700 (MST)</i>
<p>I read with interest the accounts of alarm silencing within the medical environment. In my position as a clinical engineer, I have spent many hours evaluating medical equipment for purchase and have seen the same issues wrt *all* medical equipment.</p>
<p>Specifically with infusion pumps - most do have some type of indication that they are being operated on battery - sometimes it's a positive indication (a battery icon lit up on the front panel) and sometimes it's a negative indication (an AC plug lit
up on the front panel). Most pumps do have an alarm to indicate that the battery is being depleted - usually a two stage alarm - one which alarms half an hour before the battery depletes and then one which alarms right before the battery depletes and the
equipment powers off (if it is not plugged in immediately). There are also some battery management menu items in later model pumps. Lastly, most personnel are trained in the use of the equipment - in fact because of some voluntary regulatory requirements
(Joint Commission on Accreditation of Hospitals - JCAHO for short), hospitals are required to document that training has occurred *and* prove proficiency in the use of the equipment they need to use in the discharging of their duties.</p>
<p>Even with the above, occurrences like those described in the posts happen. There are several things going on - first, in an ICU, a nurse is *bombarded* with many different pieces of equipment, which for the most part have slightly different
operating/user interfaces and different purposes. Mistakes are bound to happen. Second, if a hospital has not standardized on one manufacturer for a certain type of device, the user has yet another interface/another combination to worry about - it's kind
of like going between MS-DOS, UNIX, Windows, Macintosh, etc - little things can make a big difference (this is a big issue for me as I investigated medical device incidents in the hospital - not to mention materials management wanting to save money by
standardizing on one manufacturer).</p>
<p>I know that in my current position, I'm trying to reduce the number of interfaces that clinicians are dealing with - we routinely tell medical manufacturers that we want fewer/smaller devices that have a single interface - as well as integration
between devices for better information display - i.e. in one place. I know that the future of medical devices will eventually be some sort of transduction mechanism hooked to a PC or some computer which does data gathering, processing and dissemination.
Until then, we will have to deal with the onesies and twosies and incongruent mix of technologies and concentrate on training, training and training along with striving for standardization and reduction of different interfaces for clinicians.</p>
<p>Lastly, what I find interesting is that we used to tell the clinicians that the technology was not there to replace them - i.e., *look* at your patient - the technology was merely there to assist them by giving them more<br>
information. Sometimes if the clinicians are pressed for time, they lose that perspective - and yes, sometimes they are intimidated by the technology. I'd venture to say that producing medical devices is probably one of the more demanding pursuits because
of the regulatory jungle, the nature of the business (saving lives) and the broad range of technical skills of clinicians.</p>
<address>Bridget Moorman, Clinical Engineer, Kaiser Permanente</address>
<hr>
<h3>
<a name="subj9.3" href="#subj9.3" id="subj9.3"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Re: Alarm and alarm-silencing risks in medical equipment</h3>
<address>Erik Hollnagel &lt;<a href="mailto:Erik.Hollnagel@hrp.no">Erik.Hollnagel@hrp.no</a>&gt;</address>
<i>Mon, 04 Dec 1995 08:57:35 +0100</i>
<p>It is interesting to read the recent stories about the risks in silencing alarms. The problem is well known in the process industry, but on a much larger scale. Instead of having a single or a few alarms, there are hundreds or thousands. A nuclear
power plant can easily have several thousand alarms, and one of the Norwegian off-shore installations is known to have about 15.000 alarms that go into the control room.</p>
<p>The reason for this proliferation is the use of information technology. In the "old" days, alarms had to be announced via an annunciator tile, and there was a limit to how many annunciator tiles one could put in a panel or on a wall. Not so with
computers. Alarms can be produced simply by writing them to a screen, and the capacity of the screen is unlimited. That is, assuming that the operators are able to scroll through all the alarms and find the important ones.</p>
<p>This has led to the art of alarm filtering, which uses often complicated logic to supress alarms that are not relevant at the moment. Note the use of the term RELEVANT. This is where the problem lies, because it requires that all conceivable situations
- or at least all the important ones - can be analysed in advance. Quite apart from the problem of software reliability (of the filtering algorithms) this touches upon the problems of risk analysis and interface design.</p>
<p>To return to alarm silencing, this is clearly a problem in control rooms as well as in hospitals. It is a problem for the doctors as well as the patients. When alarms occur frequently, as during an accident, various types of visual and auditory signals
are used to attract the attention of operators. But in the medium and long term these signals are seen as distracting (which they are) and useless (which they should not be) and are hence ignored. This is a simple fact of human nature that designers
should acknowledge. The risks in designing alarm systems without considering the users' ability to respond appropriately are clearly substantial. it is a problem that is taken very seriously in the industries. But specific spectacular examples of ignoring
alarms are welcome.</p>
<p>One that comes to mind is the pilot's comment in the Lauda Air crash in 1991. According to the transcript from the CVR, the pilot said: "But, ah, you know it's a - it doesn't really, it's just an advisory thing, I don't ah -". This was in response to
the cockpit warning light. Six minutes later the plane had crashed.</p>
<address>Fax: +47.6918.7109<br>
Erik Hollnagel, Ph.D., Principal Advisor, OECD Halden Reactor Project<br>
P. O. Box 173, N-1751 Halden, Norway +47.6918.3100; <a href="mailto:Erik.Hollnagel@hrp.no">Erik.Hollnagel@hrp.no</a>
</address>
<hr>
<h3>
<a name="subj9.4" href="#subj9.4" id="subj9.4"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Re: Alarm and alarm-silencing risks in medical equipment</h3>
<address>Jay Harrell &lt;<a href="mailto:Jay.Harrell@gtri.gatech.edu">Jay.Harrell@gtri.gatech.edu</a>&gt;</address>
<i>Sat, 2 Dec 1995 15:32:01 -0500</i>
<p>Cliff Sojourner's article (<a href="/Risks/17/50">RISKS-17.50</a>, in response to John Strohm's article) struck a nerve with me too. All the medical monitors are great technology but apparently the tolerances are set for far too many false alarms
to be safe in the real world. I suppose that each manufacturer wants to be sure it isn't their equipment that fails to give a warning early enough - that way a failure can be blamed on the person watching the monitor, but the end result is that real
problems go unnoticed for long periods.</p>
<p>Last spring my two-month-old nephew was on a morphine IV pump after surgery, along with all the various monitors and alarms Cliff mentioned. The heart rate monitor repeatedly alarmed and the nurses would come in and silence it, telling us it was
normal. Unfortunately, the monitor didn't have another alarm that said there was a real problem. It turns out my nephew was getting a morphine overdose and his heart rate really was getting dangerously low. This was only discovered after persistent
nagging on the part of the mother and grandmother who were there the whole night and watched the monitor themselves. Finally they got someone to pay enough attention and he was transferred to ICU and antidote was administered. It was touch and go the next
twelve hours or so, but he's fine now. But I wonder what we would have been told the cause of death was had there been no family member there and awake.</p>
<p>As Cliff wrote: &gt; The risk here is that a real life-threatening situation would<br>
&gt; not be discovered in time to help the patient. ...</p>
<p>In this case the situation was discovered in time, but without much margin.</p>
<address>Jay Harrell, Atlanta, Georgia</address>
<hr>
<h3>
<a name="subj9.5" href="#subj9.5" id="subj9.5"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Re: Alarm and alarm-silencing risks in medical equipment</h3>
<address>Kenneth Albanowski &lt;<a href="mailto:kjahds@kjahds.com">kjahds@kjahds.com</a>&gt;</address>
<i>Sun, 3 Dec 1995 16:08:49 -0500 (EST)</i>
<p>On 30 Nov 1995 <a href="mailto:SOJOURNER_CLIFF@tandem.com">SOJOURNER_CLIFF@tandem.com</a> wrote about visual and audible alarms used in an Newborn Intensive Care Unit, and how false alarms are common, and how they are regularly silenced via a cut-off
switch:</p>
<p>The initial problem of ignored alarms is of course quite troublesome, but I wonder about a simpler but more insidious risk: are alarming noises _harming_ the patients, simply by their existence? Certainly, they aren't<br>
going to be bone-shaking klaxons, but if someone desperately needs rest, or if their sensory nerves aren't yet fully formed, can we truly say that this is a good environment for them to be in?</p>
<p>I feel safe in saying the current risk is minimal, and perhaps nonexistent, but that isn't a reason to ignore the issue. The science of user-interfaces is still in development, and we mustn't forget that a user is anybody in the room, be they human or
animal, asleep or awake, participants or not. Learning when to avoid using a particular type of user-interface element (like an audible alarm) is just as important as learning which elements should be used in the first place.</p>
<p>Here, some obvious solutions present themselves: visible alarms (like rotating police-car style lights) that are highly visible, but shaded so they are only visible to people standing up. Such a light would be obvious the instant you enter the room,
but not disturb the patients. (A minor risk here is that of creating problems for short, or wheelchair using, staff members.)</p>
<p>In a different (and unfortunately much more RISKy vain) one could use an entirely different precept of how alarms should be handled, and give staff electronic devices (pagers, etc.) that will be activated by a central computer on any alarm condition in
their vicinity or area of interest.</p>
<p>Both lose the value (immediacy, direction, and information content) of an audible alarm, but avoid the problem of alarming the folks who don't need to be alarmed in the first place.</p>
<address>Kenneth Albanowski (<a href="mailto:kjahds@kjahds.com">kjahds@kjahds.com</a>, CIS: 70705,126)</address>
<hr>
<h3>
<a name="subj9.6" href="#subj9.6" id="subj9.6"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Re: Alarm and alarm-silencing risks in medical equipment</h3>
<address>Steve Branam - Hub Products Engineering &lt;<a href="mailto:branam@dechub.lkg.dec.com">branam@dechub.lkg.dec.com</a>&gt;</address>
<i>Mon, 04 Dec 95 13:03:42 EST</i>
<p>Unreliable warning systems have been problematic for centuries (hence the tale of the boy who cried wolf). We quickly learn to ignore them so we can continue with real work. However, the danger is that we get used to expecting them to be
unreliable.</p>
<p>While in high school I once borrowed a neighbor's family car. They told me, "Oh, by the way, you can ignore that oil light, it's been on for ages." You can guess what comes next. In the middle of the night as I am returning home, the thing throws a
rod, leaving a trail of engine parts on the road. An indicator of imminent failure alerted them to a well-known maintenance issue, yet they completely ignored it.</p>
<p>The risk is the age old one of complacency. People get used to complex technological devices being flaky. When yet another device seems to be acting up, they don't take it seriously, even when someone's life depends on its proper operation. As an
engineer, I find this behavior totally incomprehensible, but it is something I have to expect from users. Unfortunately, I can only go so far in preventing a user from doing something stupid. Worse, I can never fully anticipate the ways in which the
system can be abused and misused. This seems to be more a problem of psychology than technology. There is no bug for me to fix if a user chooses to ignore an alarm condition and insists on continuing to run.</p>
<p>This problem is compounded by uncoordinated and unprioritized alarms. The multiple systems monitoring a patient are all clamoring for attention as the one thing that needs attending to. In reality only some of them may really be pertinent, while others
can be safely ignored for the moment. Imagine working in an environment where a half dozen little crises seem to be erupting every moment, despite the fact that everything is under control. It makes it hard to tell when things go out of control.</p>
<address>Steve</address>
<hr>
<h3>
<a name="subj9.7" href="#subj9.7" id="subj9.7"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Re: Alarm and alarm-silencing risks in medical equipment</h3>
<address>Robert J Horn &lt;<a href="mailto:rjh@world.std.com">rjh@world.std.com</a>&gt;</address>
<i>Sat, 2 Dec 1995 19:26:43 -0500</i>
<p>The issue of alarms and alarm suppression in a hospital environment is a rather complex one. From time to time IEEE EMB (the bio-med engineering magazine) discusses the problems involved. There is a fundamental conflict in many hospital settings:</p>
<ol>
<li>There are a great many machines and sensors providing crucial information, life-critical services, etc. in place. Each of them is designed with visible and audible warning and danger indicators of various sorts.</li>
<li>The medical staff sometimes go into sensory overload with all the noises. This has led to dangerous situations.</li>
</ol>
This is a valuable area to study and pursue mechanisms for improvement. Don't expect any simplistic answer to work. For every situation where it is obvious that a warning indicator would have saved a life, there is another situation where that same
indicator would cost a life. Often you must place this life-critical decision in the hands of the medical staff at the time.
<address>R Horn <a href="mailto:rjh@world.std.com">rjh@world.std.com</a>
</address>
<hr>
<h3>
<a name="subj9.8" href="#subj9.8" id="subj9.8"><img border="0" src="/Images/Misc/flash.gif" width="14" height="14" alt=""></a> Re: Alarm and alarm-silencing risks in medical equipment</h3>
<address>Rochelle Grober &lt;<a href="mailto:rocky@hal.com">rocky@hal.com</a>&gt;</address>
<i>Mon, 4 Dec 1995 16:56:36 -0800 (PST)</i>
<p>It appears that the medical equipment industry is traversing the same ground with regards to audible alarms as the military and space industries crossed decades ago.</p>
<p>In both the space and military applications, it has long been known that too high a false alarm rate will cause human operators to either ignore alarms from that system, or shut them off. In neither industry was this considered a "good" thing, so most
RFP's would specify the maximum false alarm rate allowable for a system. In some systems, this meant that some valid alarm situations might go unannounced for a time, but the system designs usually required that a real alarm situation would be identified
within a specified time. These two (and, of course there were others) requirements led to both hardware and software designs that attempt to filter out transient noise and that also track suspect records over time to identify alarms in both noisy and
lossy environments.</p>
<p>In most instances, both hardware and software designs are modified to provide the most capability in handling these problems.</p>
<p>In the case of some satellite communications, data frames could be marked at transmitting end as to whether all the data in the various fields (i.e. from the various instruments) was the latest and most likely reliable, or old (no new info from last
frame) and suspect. On the receiving end, the entire frame could be marked as to whether the broadcast was received complete, partially or not at all. This still presented too much alarm data, and so the data is passed to diagnostic software that tracks
states from frame to frame, accumulating historical information and watching for thresholds and other types of trend information to generate alarms at consoles for human monitoring. Of course, if done improperly, the system can miss alarms, but the groups
writing this software are supposed to thoroughly test it, and run both filtered and non-filtered versions in simulation and early operations to verify the software (along with all the other software verification processes).</p>
<p>If the medical industry looked around at other safety critical industries that had trod this path before, some of these risks from too frequent alarms could be quickly reduced or eliminated.</p>
<p>But, I guess this is the case of the risk of those ignorant of history are doomed to repeat it :-/</p>
<address>--Rocky</address>

        <nav><div class="btns">
                                                <a href="/Risks/17/50" title="Volume 17 Issue 50" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-left"></i></a>
                                <a href="/Risks/17/index" title="Volume 17 Index" itemprop="relatedLink"><i class="fad fa-fw fa-list"></i></a>
                                                    <a href="/Risks/17/52" title="Volume 17 Issue 52" itemprop="relatedLink"><i class="fad fa-fw fa-arrow-right"></i></a>
                                        <a href="mailto:risks@csl.sri.com" title="Submit an article to RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-envelope"></i></a>
            <a href="mailto:lindsay.marshall@newcastle.ac.uk?subject=Risks+Problem+17.51" title="Report a problem with this issue" itemprop="relatedLink"><i class="fad fa-fw fa-bug"></i></a>
            <a href="/Risks/archive/17/risks-17.51.gz" title="Fetch this issue as compressed plaintext" itemprop="relatedLink"><i class="fad fa-fw fa-cloud-download-alt"></i></a>
            <a href="/Risks/latest" title="The latest issue" itemprop="relatedLink"><i class="fad fa-fw fa-fast-forward"></i></a>
                            <a href="/Risks/" title="Information about RISKS" itemprop="relatedLink"><i class="fad fa-fw fa-info"></i></a>
                                </div>
        <div class="srch">
            <form action="/Risks/search" method="get">
                <label>Search RISKS <input type="text" name="query" placeholder="Query String"></label>
                <button type="submit"><i class="fad fa-fw fa-search"></i></button>
            </form>
        </div>
        <div class="clear"></div>
    </nav><p class="problems">Please report problems with the web pages to <a href="mailto:lindsay.marshall@ncl.ac.uk?subject=Problem+with+RISKS+17.51">the maintainer</a></p>

    <div id="totop">
        <i class="fas fa-chevron-up"></i>Top
    </div>

    <script src="https://kit.fontawesome.com/f38fd5f4bf.js" crossorigin="anonymous"></script><script src="https://code.jquery.com/jquery-3.5.1.min.js"></script><script>
	var base = '/Risks';

	    function hostname(url)
    {
        var match = url.match(/:\/\/(www[0-9]?\.)?(.[^/:]+)/i);
        return match != null && match.length > 2 && typeof match[2] === 'string' && match[2].length > 0 ? match[2] : null;
    }

    function domain(url) {
        var host = hostname(url);
        
        if (host != null)
        {
            var parts = host.toLowerCase().split('.').reverse();
            
            if (parts != null && parts.length > 1)
            {
                for (var x in parts)
                {
                    if (parts[x].length > 3 || (parts[x].length == 3 && x > 0))
                    {
                        return parts[x];
                    }
                }
            }
        }
        return '';
    }

	$(function(){
	        $('.shield').on('click', function(e){
        e.preventDefault();
                    alert('Site privacy analysis in process of being implemented (and may never get released...)');
            });
	})
    </script><script src="/Risks/assets/js/risksmzr2.js"></script><script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"></script><script>
     WebFont.load({
        google: {
          families: ['Open Sans']
        }
      });
    </script>
</body>
</html>
